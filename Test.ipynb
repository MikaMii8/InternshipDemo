{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is best to be aware of these changes, the documentation I was initially referring to was outdated.: \n",
    "https://github.com/run-llama/llama_index/blob/main/docs/docs/changes/deprecated_terms.md\n",
    "\n",
    "Reference Code: https://docs.llamaindex.ai/en/stable/examples/agent/openai_agent_with_query_engine/\n",
    "\n",
    "Document Summary: https://docs.llamaindex.ai/en/stable/examples/index_structs/doc_summary/DocSummary/\n",
    "\n",
    "List of vector stores:https://docs.llamaindex.ai/en/stable/module_guides/storing/vector_stores/\n",
    "\n",
    "RAG agent: https://docs.llamaindex.ai/en/stable/use_cases/q_and_a/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: type 'exit' to stop chatting with bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted and grouped lyrics by album into text files in the 'data' directory.\n",
      "All lyrics combined into 'data\\master_lyrics_by_album.txt'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "\n",
    "# load environment variables from .env file, API key is stored in the .env file.\n",
    "load_dotenv()\n",
    "\n",
    "# Load the CSV file with the specified encoding\n",
    "df = pd.read_csv('lyrics.csv', encoding='ISO-8859-1')\n",
    "data_path = Path(\"data\")\n",
    "data_path.mkdir(exist_ok=True)\n",
    "\n",
    "def sanitize_filename(name):\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', \"\", name)\n",
    "\n",
    "# lyrics stored by 'Album' name\n",
    "grouped = df.groupby(['album', 'track_n', 'track_title', 'artist', 'year'])\n",
    "album_files = {}\n",
    "for (album, track_n, track_title, artist, year), group in grouped:\n",
    "    sanitized_album_name = sanitize_filename(album.replace(' ', '_'))\n",
    "    album_file_path = data_path / f\"{sanitized_album_name}.txt\"\n",
    "    if sanitized_album_name not in album_files:\n",
    "        album_files[sanitized_album_name] = open(album_file_path, \"w\", encoding='utf-8')\n",
    "    fp = album_files[sanitized_album_name]\n",
    "    \n",
    "    # track details and lyrics to the album file\n",
    "    fp.write(\n",
    "        f\"Artist: {artist}\\n\"\n",
    "        f\"Album: {album}\\n\"\n",
    "        f\"Track Title: {track_title}\\n\"\n",
    "        f\"Track Number: {track_n}\\n\"\n",
    "        f\"Year: {year}\\n\"\n",
    "        f\"Lyric:\\n\"\n",
    "    )\n",
    "    for lyric in group['lyric']:\n",
    "        fp.write(f\"{lyric}\\n\")\n",
    "    fp.write(\"\\n\\n\")  # Add a newline between each song's lyrics\n",
    "\n",
    "# closing the files\n",
    "for fp in album_files.values():\n",
    "    fp.close()\n",
    "\n",
    "print(f\"Extracted and grouped lyrics by album into text files in the '{data_path}' directory.\")\n",
    "\n",
    "# combine all album lyrics into one master file\n",
    "master_file_path = data_path / \"master_lyrics_by_album.txt\"\n",
    "with open(master_file_path, \"w\", encoding='utf-8') as master_fp:\n",
    "    for album_file in data_path.glob(\"*.txt\"):\n",
    "        with open(album_file, \"r\", encoding='utf-8') as fp:\n",
    "            master_fp.write(fp.read())\n",
    "            master_fp.write(\"\\n\\n\")  \n",
    "\n",
    "print(f\"All lyrics combined into '{master_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Q & A Bot (based on RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Entering Chat REPL =====\n",
      "Type \"exit\" to exit.\n",
      "\n",
      "Added user message to memory: Hi can you make up a song based on the Red album?\n",
      "=== Calling Function ===\n",
      "Calling function: text_data with args: {\"input\":\"Red album\"}\n",
      "Got output: Taylor Swift's \"Red\" album was released in 2012 and features tracks like \"State of Grace,\" \"Red,\" \"Starlight,\" \"Begin Again,\" \"Holy Ground,\" \"Sad Beautiful Tragic,\" \"The Lucky One,\" \"22,\" \"I Almost Do,\" \"All Too Well,\" \"The Last Time,\" \"Everything Has Changed,\" \"Treacherous,\" \"I Knew You Were Trouble,\" and \"Stay Stay Stay.\"\n",
      "========================\n",
      "\n",
      "Assistant: Here is a made-up song based on Taylor Swift's \"Red\" album:\n",
      "\n",
      "(Verse 1)\n",
      "In the state of grace, we found our way\n",
      "Painting the town red, under starlight's sway\n",
      "Begin again, on holy ground we stand\n",
      "A sad beautiful tragic love, like grains of sand\n",
      "\n",
      "(Chorus)\n",
      "We're the lucky ones, feeling 22\n",
      "I almost do, but all too well I knew\n",
      "The last time we danced, everything changed\n",
      "In treacherous love, trouble stayed the same\n",
      "\n",
      "(Verse 2)\n",
      "I knew you were trouble from the start\n",
      "But I stayed, stay, stayed in your heart\n",
      "The memories linger, like a haunting melody\n",
      "In the echoes of our love, I find my solace and plea\n",
      "\n",
      "(Bridge)\n",
      "Red like the passion that burns within\n",
      "A kaleidoscope of emotions, where do I begin?\n",
      "The colors of our love, a masterpiece untold\n",
      "In the symphony of heartbreak, our story unfolds\n",
      "\n",
      "(Chorus)\n",
      "We're the lucky ones, feeling 22\n",
      "I almost do, but all too well I knew\n",
      "The last time we danced, everything changed\n",
      "In treacherous love, trouble stayed the same\n",
      "\n",
      "(Outro)\n",
      "As the album plays, memories flood my mind\n",
      "In the echoes of \"Red,\" our love we find\n",
      "A timeless tale of joy and pain\n",
      "In the melody of our love, forever we remain\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext\n",
    "from llama_index.readers.file import FlatReader\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding, OpenAIEmbeddingModelType\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.agent.openai import OpenAIAgent\n",
    "import os\n",
    "\n",
    "# API key\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "\n",
    "# openAI Embedding Model\n",
    "embedding_model = OpenAIEmbedding(\n",
    "    api_key=openai_api_key, \n",
    "    model=OpenAIEmbeddingModelType.TEXT_EMBED_ADA_002\n",
    ")\n",
    "\n",
    "# using FlatReader for reading text files\n",
    "file_extractor = {\".txt\": FlatReader()}\n",
    "\n",
    "# load documents from the specified directory\n",
    "reader = SimpleDirectoryReader(\"./data\", file_extractor=file_extractor)\n",
    "documents = reader.load_data()\n",
    "\n",
    "# create a Vector Store Index and save it there, we can also do this manually.\n",
    "vector_index = VectorStoreIndex.from_documents(documents)\n",
    "vector_index.storage_context.persist(persist_dir=\"./storage/text_data\")\n",
    "\n",
    "# query engine\n",
    "query_engine = vector_index.as_query_engine(similarity_top_k=10)\n",
    "query_engine_tool = QueryEngineTool(\n",
    "    query_engine=query_engine,\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"text_data\",\n",
    "        description=\"Provides creative answers based on the text data loaded.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Start chatting with the agent!\n",
    "agent = OpenAIAgent.from_tools([query_engine_tool], model_name=\"gpt-4o\",verbose= True)\n",
    "agent.chat_repl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
