{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is best to be aware of these changes, the documentation I was initially referring to was outdated.: \n",
    "https://github.com/run-llama/llama_index/blob/main/docs/docs/changes/deprecated_terms.md\n",
    "\n",
    "Reference Code: https://docs.llamaindex.ai/en/stable/examples/agent/openai_agent_with_query_engine/\n",
    "\n",
    "Document Summary: https://docs.llamaindex.ai/en/stable/examples/index_structs/doc_summary/DocSummary/\n",
    "\n",
    "List of vector stores:https://docs.llamaindex.ai/en/stable/module_guides/storing/vector_stores/\n",
    "\n",
    "RAG agent: https://docs.llamaindex.ai/en/stable/use_cases/q_and_a/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: type 'exit' to stop chatting with bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted and grouped lyrics by album into text files in the 'data' directory.\n",
      "All lyrics combined into 'data\\master_lyrics_by_album.txt'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "\n",
    "# load environment variables from .env file, API key is stored in the .env file.\n",
    "load_dotenv()\n",
    "\n",
    "# Load the CSV file with the specified encoding\n",
    "df = pd.read_csv('lyrics.csv', encoding='ISO-8859-1')\n",
    "data_path = Path(\"data\")\n",
    "data_path.mkdir(exist_ok=True)\n",
    "\n",
    "def sanitize_filename(name):\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', \"\", name)\n",
    "\n",
    "# lyrics stored by 'Album' name\n",
    "grouped = df.groupby(['album', 'track_n', 'track_title', 'artist', 'year'])\n",
    "album_files = {}\n",
    "for (album, track_n, track_title, artist, year), group in grouped:\n",
    "    sanitized_album_name = sanitize_filename(album.replace(' ', '_'))\n",
    "    album_file_path = data_path / f\"{sanitized_album_name}.txt\"\n",
    "    if sanitized_album_name not in album_files:\n",
    "        album_files[sanitized_album_name] = open(album_file_path, \"w\", encoding='utf-8')\n",
    "    fp = album_files[sanitized_album_name]\n",
    "    \n",
    "    # track details and lyrics to the album file\n",
    "    fp.write(\n",
    "        f\"Artist: {artist}\\n\"\n",
    "        f\"Album: {album}\\n\"\n",
    "        f\"Track Title: {track_title}\\n\"\n",
    "        f\"Track Number: {track_n}\\n\"\n",
    "        f\"Year: {year}\\n\"\n",
    "        f\"Lyric:\\n\"\n",
    "    )\n",
    "    for lyric in group['lyric']:\n",
    "        fp.write(f\"{lyric}\\n\")\n",
    "    fp.write(\"\\n\\n\")  # Add a newline between each song's lyrics\n",
    "\n",
    "# closing the files\n",
    "for fp in album_files.values():\n",
    "    fp.close()\n",
    "\n",
    "print(f\"Extracted and grouped lyrics by album into text files in the '{data_path}' directory.\")\n",
    "\n",
    "# combine all album lyrics into one master file\n",
    "master_file_path = data_path / \"master_lyrics_by_album.txt\"\n",
    "with open(master_file_path, \"w\", encoding='utf-8') as master_fp:\n",
    "    for album_file in data_path.glob(\"*.txt\"):\n",
    "        with open(album_file, \"r\", encoding='utf-8') as fp:\n",
    "            master_fp.write(fp.read())\n",
    "            master_fp.write(\"\\n\\n\")  \n",
    "\n",
    "print(f\"All lyrics combined into '{master_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Q & A Bot (based on RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext\n",
    "from llama_index.readers.file import FlatReader\n",
    "from llama_index.embeddings.openaifrom  import OpenAIEmbedding, OpenAIEmbeddingModelType\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.agent.openai import OpenAIAgent\n",
    "import os\n",
    "\n",
    "# API key\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Entering Chat REPL =====\n",
      "Type \"exit\" to exit.\n",
      "\n",
      "Added user message to memory: when was REdreleased\n",
      "=== Calling Function ===\n",
      "Calling function: text_data with args: {\"input\":\"When was REd released\"}\n",
      "Got output: Red was released in 2012.\n",
      "========================\n",
      "\n",
      "Assistant: Red was released in 2012.\n",
      "\n",
      "Added user message to memory: \n",
      "Assistant: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext\n",
    "from llama_index.readers.file import FlatReader\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding, OpenAIEmbeddingModelType\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.agent.openai import OpenAIAgent\n",
    "import os\n",
    "\n",
    "# API key\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "\n",
    "# openAI Embedding Model\n",
    "embedding_model = OpenAIEmbedding(\n",
    "    api_key=openai_api_key, \n",
    "    model=OpenAIEmbeddingModelType.TEXT_EMBED_ADA_002\n",
    ")\n",
    "\n",
    "# using FlatReader for reading text files\n",
    "file_extractor = {\".txt\": FlatReader()}\n",
    "\n",
    "# load documents from the specified directory\n",
    "reader = SimpleDirectoryReader(\"./data\", file_extractor=file_extractor)\n",
    "documents = reader.load_data()\n",
    "\n",
    "# create a Vector Store Index and save it there, we can also do this manually.\n",
    "vector_index = VectorStoreIndex.from_documents(documents)\n",
    "vector_index.storage_context.persist(persist_dir=\"./storage/text_data\")\n",
    "\n",
    "# query engine\n",
    "query_engine = vector_index.as_query_engine(similarity_top_k=10)\n",
    "query_engine_tool = QueryEngineTool(\n",
    "    query_engine=query_engine,\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"text_data\",\n",
    "        description=\"Provides answers based on the text data loaded.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Start chatting with the agent!\n",
    "agent = OpenAIAgent.from_tools([query_engine_tool], model_name=\"gpt-4\",verbose= True)\n",
    "agent.chat_repl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Package(s) not found: os\n"
     ]
    }
   ],
   "source": [
    "pip show os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: nest-asyncioNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Version: 1.6.0\n",
      "Summary: Patch asyncio to allow nested event loops\n",
      "Home-page: https://github.com/erdewit/nest_asyncio\n",
      "Author: Ewald R. de Wit\n",
      "Author-email: ewald.de.wit@gmail.com\n",
      "License: BSD\n",
      "Location: C:\\Users\\k425167\\AppData\\Roaming\\Python\\Python312\\site-packages\n",
      "Requires: \n",
      "Required-by: ipykernel, llama-index-core, llama-index-legacy\n"
     ]
    }
   ],
   "source": [
    "pip show nest-asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: llama-index-core\n",
      "Version: 0.10.61\n",
      "Summary: Interface between LLMs and your data\n",
      "Home-page: https://llamaindex.ai\n",
      "Author: Jerry Liu\n",
      "Author-email: jerry@llamaindex.ai\n",
      "License: MIT\n",
      "Location: c:\\Users\\k425167\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\n",
      "Requires: aiohttp, dataclasses-json, deprecated, dirtyjson, fsspec, httpx, nest-asyncio, networkx, nltk, numpy, openai, pandas, pillow, PyYAML, requests, SQLAlchemy, tenacity, tiktoken, tqdm, typing-extensions, typing-inspect, wrapt\n",
      "Required-by: llama-index, llama-index-agent-openai, llama-index-cli, llama-index-embeddings-openai, llama-index-indices-managed-llama-cloud, llama-index-llms-openai, llama-index-multi-modal-llms-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index-readers-file, llama-index-readers-llama-parse, llama-parse\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show llama_index.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: llama-index-embeddings-openai\n",
      "Version: 0.1.11\n",
      "Summary: llama-index embeddings openai integration\n",
      "Home-page: \n",
      "Author: Your Name\n",
      "Author-email: you@example.com\n",
      "License: MIT\n",
      "Location: c:\\Users\\k425167\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\n",
      "Requires: llama-index-core\n",
      "Required-by: llama-index, llama-index-cli\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show llama_index.embeddings.openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: llama-index-readers-file\n",
      "Version: 0.1.32\n",
      "Summary: llama-index readers file integration\n",
      "Home-page: \n",
      "Author: Your Name\n",
      "Author-email: you@example.com\n",
      "License: MIT\n",
      "Location: c:\\Users\\k425167\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\n",
      "Requires: beautifulsoup4, llama-index-core, pypdf, striprtf\n",
      "Required-by: llama-index\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show llama_index.readers.file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
